First of all, after installing docker on your machine & add "Dockerfile"
Initially, the container is empty.

You have to set the baseImage, in our case it's (Node)
    FROM node:18        # by default it's set to the latest version 
         
COPY src dist
# NOTE: To set a the working directory for any future (RUN, CMD, COPY, ADD, ...) we use ==>  "WORKDIR"
    WORKDIR /app        # this folder will be in the root of the container.

After adding node image, we want to install all dependencies for our application
    COPY package.json .

# NOTE: To run a command:    "RUN"
    RUN npm install       # NOTE: after installing node, our server can use (npm)

To copy all files like "index.js" from the working directory to the server
    COPY . . 


You can setup the port to use the container server on with (EXPOSE)
    EXPOSE 4000
Now, you're able to run this server using (npm start) or whatever.
    CMD [ "npm", "start" ]



    =======================================================================================
    =======================================================================================


Since we finished (Dockerfile), we can run it from terminal with this command:
    $ docker build -t first-node-app .
"first-node-app"        ==>     gives the built image a name.
"."                     ==>     the path to run "Dockerfile" from (by default it searches for (Dockerfile)) 
// You can also say    "./Dockerfile"

// Now, your image is successfully created. 
// To see all images in docker:
    $ docker image ls 


    =======================================================================================
    =======================================================================================


Once we created the image, we can run it to create a container.
    $ docker run --name express-node-app-container express-node-app         # To run image and give the container a name (express-node-app-container) 

To show all running containers: 
    $ docker ps


To remove a container:
    $ docker rm <container-name> 


To run the container in "Background" and be able to use other commands we add a flag -d before the image-name like this:
    $ docker run --name second-node-app-container -d first-node-app

If we try to remove a container but it's running. We have to force it with (-f) force flag..


NOTE: the (EXPOSE) we used above is just for documentation. 
But to make the server listen on some port we do it like this:
    $ docker run --name first-node-app-container -d -p 1000:4000 first-node-app
// This means forward the port 1000 of my machine to port 4000 in the container that I've previously set in (EXPOSE)



    =======================================================================================
    =======================================================================================


To open an interactive terminal from the container:
    $ docker exec -it first-node-app-container bash
By default, it will use the (root) user. But you can create and use another user.

In this terminal, you can use (ls), (pwd), ... to access files in the container.

If you check all files in the docker container, you'll find that you've copied "Node_Modules" 
    which contains dev-dependencies that you don't need in production & .env that are your env variables.

To hide these files from beiing copied to the container we use (.dockerignore) file:
we usually hide (Dockerfile) 
#You don't need to copy it as you've already run it.

To exit from container terminal to default terminal: 
    $ exit

// NOTE: when you hit $ls  You'll find "node_modules" 
// But it's not from copying files but from running "npm install"


    =======================================================================================
    =======================================================================================


NOTE: we separated (COPY package.json) & (COPY . .)
because docker can cash if no change happended to (package.json)
but if we copy all files in the same command, every time we build an image all modules will be reinstalled.


    =======================================================================================
    =======================================================================================


NOTE: when I change the file directory, I have to change the image not only the container to get latest updates.


    =======================================================================================
    =======================================================================================

To run the logs of the server (container)
    $ docker logs <CONTRAINER-NAME>



# To make docker server run with (nodemon), we simply put the command we specified in package.json
    CMD [ "npm", "run", "start-dev" ]   


    =======================================================================================
                                    Docker Hot Reload
    =======================================================================================

    $ docker run --name express-node-app-container -v  <FULL-PATH-OF-WORKING-DIRECTORY>:<PATH-TO-SYNC-WITH-IN-CONTAINER>  -d -p 4000:4000 express-node-app  

To prevent changes of docker container from changing the local working directory:
    - We add (readonly) after the path of the docker container. (ro)
    $ docker run --name nodemon-app-container2 -v C:/repos/Docker-Study:/app:ro -d -p 2200:4000 test-nodemon-app

NOTE: we can replace the long path of the command $(pwd)        ===>    (for linux)

NOTE: If I deleted "node_modules" the docker container will stop. as the container will sync the changes from the working directory.
// To save specified files even if they were deleted from the working directory:
/// We will add another flag -v after that the files or folder we want to save from deletion.
    $ docker run --name nodemon-app-container2 -v C:/repos/Docker-Study:/app:ro -v /app/node_modules -d -p 2200:4000 test-nodemon-app





>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Docker Compose <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
Firstly, we create a file       ==>     "docker-compose.yml"

=========
1- Specify the version of docker-compose
    version: "3"
2- Specify the services (containers) you have.
    services: 
        node-app: 
            container_name: express-node-app-container              // For example.
            build: .                                                // the starter Dockerfile path
            volumes: 
                - ./src:/app/src:ro              ### NOTE: here you can use (relative path)
            ports: 
                - "4000:4000"


// NOW, I have successfully created a "docker-compose.yml" file that holds all instructions that I was using before.
Any commnd from docker-compose, you can run like this:
    $ docker-compose --version          # to list all available options..

// To run commands in (docker-compose) you use:
    $ docker-compose up
// This will build an image, then run a container..
 

// And to run the container in the Background: 
    $ docker-compose up -d


// To stop the container:
    $ docker-compose down 




>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Environment Variables <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
To setup env variables, 
1- we can add them in the (Dockerfile) ... for example:
    ENV PORT = 4000         # declare enviroment variable 
    EXPOSE $PORT            # pass enviroment variable
// These are in (Dockerfile)


2- to pass enviroment variables as arguments in the terminal.
    with flag (--e)
    $ docker run --name container -v C:\repos\Docker-Study\src:/app/src:ro --env PORT=4000 --env NODE_ENV=development -d -p 4000:4000 docker-study-node-app
// Inside the container terminal, you can run "printenv" to list all enviroment variables.


3- an easier way to do this, is to pass a file containing env variables.
    with flag (--env-file  <FILE-PATH>)
    $ docker run --name container -v C:\repos\Docker-Study\src:/app/src:ro --env PORT=4000 --env-file ./.env NODE_ENV=development -d -p 4000:4000 docker-study-node-app





>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> Environment Variables in docker-compose <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
version: "3"
services: 
  node-app: 
    container_name: express-node-app-container              
    build: .                                                
    volumes: 
      - ./src:/app/src:ro              ### NOTE: here you can use (relative path)
    ports: 
      - "4000:4000"
    enviroment:
      - PORT=4000
      - NODE_ENV=production


// NOTE: instead of repeating common env variables, you can create a file (docker-compose) that holds the common Variables.
    and other two (docker-compose.dev & docker-compose.prod) to hold other variables.
Now, to run a container in (Development), you have to call both common & dev docker-compose:
    $ docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d
and same for (Production)


// If you want to recreate an image you have to add a flag (--build)
    $  docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d --build
 


// NOTE: we've installed dependencies twice once for the common docker-compose and another for the (dev or prod) 
// To prevent this, we can create two differnt Dockerfiles and each with its own commands.

// Another solution is to override commands in .dev & .prod





>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> MongoDB container <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
To run another container to hold out DB, we have to add another service in (docker-compose)
We go to (docker hub) and search for (MongoDB) to get the instructions to install (MongoDB) from documentation.

mongo:
    image: mongo
    restart: always
    environment:
        MONGO_INITDB_ROOT_USERNAME: root
        MONGO_INITDB_ROOT_PASSWORD: example
    
NOTE: we can call the service whatever we want.
NOTE: we don't build an image, we just run the container from this public image.

Now when we run:  $ docker-compose -f docker-compose.yml -f docker-compose.dev.yml up -d --build
    we'll get two containers, one for node & one for mongo.

And if we run docker ps, we'll see two running containers

Now, we'll use mongoose 
But we want to get the required files for the DATABASE_URI
 `mongodb://username:password@host:port`;

To get all data about the container:
    $ docker inspect node-express-app_mongo_1
This allows us to get all the data:
To get the host: 
    - in Networks field, you'll find for example "docker-study-default"
    and another fileds like "IP address"





// To list all volumes on your machine:
    $ docker volume ls

// To delete any of these volumes: 
    $ docker volume rm <Volume-Name>

// To remove all volumes that currently unused or there's no container uses it:
    $ docker volume prune 


// NOTE: after creating volumes and choose a path for it
    // When we delete the container and create a new one, Data remains.



// NOTE: 
    // If you want to delete volumes with the container, you can add a flag (-v) after the (down) command.


// To connect to DB container created from terminal:
    $ docker exec -it <MONGO-CONTAINER-NAME> mongosh -u <MONGO-USERNAME> -p <MONGO-PASSWORD> 
    $ docker exec -it docker-study-mongo-1 mongosh -u root -p example

From mongo terminal, you can create, delete, .... show tables and so on.



mongo-express:
    is a UI tool to use mongoDB.

